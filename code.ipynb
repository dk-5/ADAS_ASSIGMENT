{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Check if GPU is available and use it\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load a pre-trained YOLOv5 model (small version for speed) from PyTorch Hub\n",
    "# This will automatically download the model if not available\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "model.to(device)\n",
    "model.eval()  # set the model to evaluation mode\n",
    "\n",
    "# Define input and output directories (update these paths)\n",
    "input_dir = \"/kaggle/input/kitti-dataset/data_object_image_2/training/image_2\"      # Directory containing your images\n",
    "output_dir = \"/kaggle/working/object_vector\"     # Directory to save processed images\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Get first 1000 image file names (assumes images are .jpg or .png)\n",
    "image_files = sorted([f for f in os.listdir(input_dir) if f.lower().endswith(('.jpg', '.png'))])[:1000]\n",
    "\n",
    "# Dictionary to store object vectors for each image\n",
    "object_vectors = {}\n",
    "\n",
    "# Timer to check processing speed (simulate ~30 FPS processing if needed)\n",
    "start_time = time.time()\n",
    "\n",
    "for idx, img_file in enumerate(image_files):\n",
    "    img_path = os.path.join(input_dir, img_file)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"Error loading image {img_path}\")\n",
    "        continue\n",
    "    \n",
    "    # Convert image from BGR (OpenCV) to RGB (model expects RGB)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Inference: move image to the same device as the model\n",
    "    results = model(img_rgb)\n",
    "    \n",
    "    # Get detections in the format: [x1, y1, x2, y2, confidence, class]\n",
    "    detections = results.xyxy[0].detach().cpu().numpy()\n",
    "    \n",
    "    # Store detections (object vector) for this image\n",
    "    object_vectors[img_file] = detections.tolist()\n",
    "    \n",
    "    # Draw detections on the image for visualization\n",
    "    for det in detections:\n",
    "        x1, y1, x2, y2, conf, cls = det\n",
    "        label = results.names[int(cls)]\n",
    "        cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "        cv2.putText(img, f\"{label} {conf:.2f}\", (int(x1), int(y1)-10), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    # Save the processed image with detections\n",
    "    output_img_path = os.path.join(output_dir, img_file)\n",
    "    cv2.imwrite(output_img_path, img)\n",
    "    \n",
    "    # Optionally, print progress every 50 images\n",
    "    if (idx + 1) % 50 == 0:\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"Processed {idx+1} images in {elapsed:.2f} seconds\")\n",
    "\n",
    "# Save the object vectors dictionary as a JSON file for later analysis\n",
    "with open(os.path.join(output_dir, \"object_vectors.json\"), \"w\") as f:\n",
    "    json.dump(object_vectors, f)\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "class CameraOnlyDetection:\n",
    "    def __init__(self, calib_file_path):\n",
    "        \"\"\"\n",
    "        Initialize the camera-only detection class with calibration parameters\n",
    "        \n",
    "        Args:\n",
    "            calib_file_path: Path to the calibration file containing camera matrices\n",
    "        \"\"\"\n",
    "        self.calib_data = self.load_calibration(calib_file_path)\n",
    "        self.image_objects = {}  # Dictionary to store detected objects from camera\n",
    "        \n",
    "    def load_calibration(self, calib_file_path):\n",
    "        \"\"\"\n",
    "        Load calibration parameters from file\n",
    "        \n",
    "        Args:\n",
    "            calib_file_path: Path to the calibration file\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing calibration matrices\n",
    "        \"\"\"\n",
    "        calib_data = {}\n",
    "        try:\n",
    "            with open(calib_file_path, 'r') as f:\n",
    "                for line in f.readlines():\n",
    "                    if ':' in line:\n",
    "                        key, value = line.split(':', 1)\n",
    "                        calib_data[key] = np.array([float(x) for x in value.split()])\n",
    "                    else:\n",
    "                        # Handle alternative format if needed\n",
    "                        parts = line.split()\n",
    "                        if len(parts) > 1:\n",
    "                            key = parts[0]\n",
    "                            values = [float(x) for x in parts[1:]]\n",
    "                            calib_data[key] = np.array(values)\n",
    "                    \n",
    "            # Reshape matrices\n",
    "            if 'P2' in calib_data:  # Camera projection matrix\n",
    "                calib_data['P2'] = calib_data['P2'].reshape(3, 4)\n",
    "            elif 'P_rect_02' in calib_data:  # Alternative naming in some KITTI formats\n",
    "                calib_data['P2'] = calib_data['P_rect_02'].reshape(3, 4)\n",
    "                \n",
    "            # Create default matrices if missing\n",
    "            if 'P2' not in calib_data:\n",
    "                print(\"Warning: P2 matrix not found in calibration file. Using default.\")\n",
    "                calib_data['P2'] = np.array([[718.856, 0, 607.1928, 0], \n",
    "                                            [0, 718.856, 185.2157, 0],\n",
    "                                            [0, 0, 1, 0]])\n",
    "                \n",
    "            # Extract camera intrinsics for distance estimation\n",
    "            if 'P2' in calib_data:\n",
    "                calib_data['fx'] = calib_data['P2'][0, 0]  # Focal length x\n",
    "                calib_data['fy'] = calib_data['P2'][1, 1]  # Focal length y\n",
    "                calib_data['cx'] = calib_data['P2'][0, 2]  # Principal point x\n",
    "                calib_data['cy'] = calib_data['P2'][1, 2]  # Principal point y\n",
    "                \n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: Calibration file not found: {calib_file_path}. Using default values.\")\n",
    "            # Default calibration values\n",
    "            calib_data['P2'] = np.array([[718.856, 0, 607.1928, 0], \n",
    "                                         [0, 718.856, 185.2157, 0],\n",
    "                                         [0, 0, 1, 0]])\n",
    "            calib_data['fx'] = 718.856\n",
    "            calib_data['fy'] = 718.856\n",
    "            calib_data['cx'] = 607.1928\n",
    "            calib_data['cy'] = 185.2157\n",
    "            \n",
    "        return calib_data\n",
    "    \n",
    "    def load_image_objects(self, objects_file_path, image_id):\n",
    "        \"\"\"\n",
    "        Load detected objects from camera\n",
    "        \n",
    "        Args:\n",
    "            objects_file_path: Path to the file containing detected objects\n",
    "            image_id: ID of the image\n",
    "        \"\"\"\n",
    "        objects = []\n",
    "        try:\n",
    "            with open(objects_file_path, 'r') as f:\n",
    "                for line in f.readlines():\n",
    "                    values = line.strip().split(' ')\n",
    "                    # Skip empty lines\n",
    "                    if len(values) < 2:\n",
    "                        continue\n",
    "                        \n",
    "                    # Try to parse standard KITTI format\n",
    "                    try:\n",
    "                        obj = {\n",
    "                            'type': values[0],\n",
    "                            'truncated': float(values[1]),\n",
    "                            'occluded': int(values[2]),\n",
    "                            'alpha': float(values[3]),\n",
    "                            'bbox': [float(values[4]), float(values[5]), float(values[6]), float(values[7])],\n",
    "                            'dimensions': [float(values[8]), float(values[9]), float(values[10])],\n",
    "                            'location': [float(values[11]), float(values[12]), float(values[13])],\n",
    "                            'rotation_y': float(values[14])\n",
    "                        }\n",
    "                        if len(values) > 15:  # If confidence score is available\n",
    "                            obj['score'] = float(values[15])\n",
    "                        objects.append(obj)\n",
    "                    except (ValueError, IndexError) as e:\n",
    "                        print(f\"Warning: Could not parse line: {line}. Error: {e}\")\n",
    "                        # Try alternative format if available\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: Object file not found: {objects_file_path}\")\n",
    "        \n",
    "        # Debug output: Print how many objects were loaded\n",
    "        print(f\"Loaded {len(objects)} objects for image {image_id}\")\n",
    "        \n",
    "        self.image_objects[image_id] = objects\n",
    "        return objects\n",
    "    \n",
    "    def estimate_distance(self, obj):\n",
    "        \"\"\"\n",
    "        Estimate distance using camera calibration and 3D object information\n",
    "        \n",
    "        Args:\n",
    "            obj: Object dictionary with dimensions and location\n",
    "            \n",
    "        Returns:\n",
    "            Estimated distance in meters\n",
    "        \"\"\"\n",
    "        # If we have 3D location from the labels, use it directly\n",
    "        if 'location' in obj and obj['location'][2] > 0:\n",
    "            # The Z coordinate is depth in camera coordinates\n",
    "            return obj['location'][2]\n",
    "        \n",
    "        # If no 3D location but we have dimensions and a bounding box, we can estimate\n",
    "        # This is a simplified approach using the apparent height of the object\n",
    "        if 'dimensions' in obj and 'bbox' in obj:\n",
    "            # Get object height in 3D space\n",
    "            obj_height_3d = obj['dimensions'][1]  # Height is usually the second dimension in KITTI\n",
    "            \n",
    "            # Get object height in image (pixels)\n",
    "            bbox = obj['bbox']\n",
    "            obj_height_px = bbox[3] - bbox[1]\n",
    "            \n",
    "            # Use the formula: real_height / distance = perceived_height / focal_length\n",
    "            # So distance = real_height * focal_length / perceived_height\n",
    "            if obj_height_px > 0:\n",
    "                distance = obj_height_3d * self.calib_data['fy'] / obj_height_px\n",
    "                return distance\n",
    "        \n",
    "        # Fallback to a default distance\n",
    "        return 10.0\n",
    "    \n",
    "    def calculate_collision_risk(self, image_id, velocity=None, time_threshold=3.0):\n",
    "        \"\"\"\n",
    "        Calculate collision risk for objects in the scene using camera data\n",
    "        \n",
    "        Args:\n",
    "            image_id: ID of the frame\n",
    "            velocity: Ego vehicle velocity (m/s)\n",
    "            time_threshold: Time threshold for collision warning in seconds\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary of objects with collision risk scores\n",
    "        \"\"\"\n",
    "        if image_id not in self.image_objects:\n",
    "            print(f\"No objects found for image {image_id} when calculating risks\")\n",
    "            return {}\n",
    "            \n",
    "        # Default velocity if not provided (50 km/h)\n",
    "        if velocity is None:\n",
    "            velocity = 13.8  # m/s\n",
    "            \n",
    "        collision_risks = {}\n",
    "        \n",
    "        for obj_idx, obj in enumerate(self.image_objects[image_id]):\n",
    "            # Skip certain object types if desired\n",
    "            if obj['type'].lower() in ['misc', 'dontcare']:\n",
    "                continue\n",
    "                \n",
    "            # Estimate distance using calibration and object data\n",
    "            distance = self.estimate_distance(obj)\n",
    "            \n",
    "            # Get lateral position relative to camera center\n",
    "            if 'location' in obj:\n",
    "                # Use X coordinate for lateral position\n",
    "                lateral_position = obj['location'][0]\n",
    "            else:\n",
    "                # Estimate from bounding box center\n",
    "                bbox = obj['bbox']\n",
    "                bbox_center_x = (bbox[0] + bbox[2]) / 2\n",
    "                # Convert to meters using calibration (simplified)\n",
    "                lateral_position = (bbox_center_x - self.calib_data['cx']) * distance / self.calib_data['fx']\n",
    "            \n",
    "            # Determine if object is in our path (simple approximation)\n",
    "            # Assume lane width is about 3.5 meters - made wider for better visualization\n",
    "            in_path = abs(lateral_position) < 2.0\n",
    "            \n",
    "            # Forward distance is the same as distance in our simplified model\n",
    "            forward_distance = distance\n",
    "            \n",
    "            # Assuming objects are stationary for worst-case scenario\n",
    "            relative_velocity = velocity\n",
    "                \n",
    "            # Calculate time to collision (TTC)\n",
    "            if forward_distance > 0 and relative_velocity > 0:  # Object is in front\n",
    "                ttc = forward_distance / relative_velocity\n",
    "            else:\n",
    "                ttc = float('inf')  # Object not in front or no relative velocity\n",
    "                \n",
    "            # Calculate collision risk score (higher for objects in our path)\n",
    "            if ttc < time_threshold and ttc > 0:\n",
    "                base_risk = 1.0 - (ttc / time_threshold)\n",
    "                # Increase risk for objects in our path, decrease for those outside\n",
    "                risk_score = base_risk * (1.0 if in_path else 0.3)\n",
    "            else:\n",
    "                risk_score = 0.0\n",
    "                \n",
    "            collision_risks[obj_idx] = {\n",
    "                'object': obj,\n",
    "                'distance': distance,\n",
    "                'lateral_position': lateral_position,\n",
    "                'in_path': in_path,\n",
    "                'forward_distance': forward_distance,\n",
    "                'ttc': ttc,\n",
    "                'risk_score': risk_score\n",
    "            }\n",
    "            \n",
    "        # Debug: print number of risks found\n",
    "        print(f\"Calculated {len(collision_risks)} collision risks for image {image_id}\")\n",
    "        # Debug: print the highest risk score\n",
    "        if collision_risks:\n",
    "            max_risk = max([r['risk_score'] for r in collision_risks.values()])\n",
    "            print(f\"Highest risk score for image {image_id}: {max_risk}\")\n",
    "            \n",
    "        return collision_risks\n",
    "    \n",
    "    def generate_warnings(self, collision_risks, risk_threshold=0.3):\n",
    "        \"\"\"\n",
    "        Generate warnings based on collision risks\n",
    "        \n",
    "        Args:\n",
    "            collision_risks: Dictionary of objects with collision risk scores\n",
    "            risk_threshold: Threshold for high risk\n",
    "            \n",
    "        Returns:\n",
    "            List of warnings\n",
    "        \"\"\"\n",
    "        warnings = []\n",
    "        \n",
    "        for obj_id, risk_data in collision_risks.items():\n",
    "            if risk_data['risk_score'] > risk_threshold:\n",
    "                obj_type = risk_data['object']['type']\n",
    "                distance = risk_data['distance']\n",
    "                ttc = risk_data['ttc']\n",
    "                in_path = risk_data['in_path']\n",
    "                \n",
    "                warning_level = 'HIGH' if risk_data['risk_score'] > 0.5 else 'MEDIUM'\n",
    "                \n",
    "                # Add more context about position\n",
    "                position_context = \"in path\" if in_path else \"outside path\"\n",
    "                \n",
    "                warning = {\n",
    "                    'level': warning_level,\n",
    "                    'message': f\"Collision warning: {obj_type} at {distance:.2f}m ({position_context}), TTC: {ttc:.2f}s\",\n",
    "                    'object_id': obj_id,\n",
    "                    'action': 'BRAKE' if risk_data['risk_score'] > 0.5 and in_path else 'ALERT'\n",
    "                }\n",
    "                \n",
    "                warnings.append(warning)\n",
    "                \n",
    "        # Debug: print number of warnings generated\n",
    "        print(f\"Generated {len(warnings)} warnings from {len(collision_risks)} collision risks\")\n",
    "                \n",
    "        return warnings\n",
    "    \n",
    "    def visualize_detections(self, image_path, image_id, save_path=None):\n",
    "        \"\"\"\n",
    "        Visualize the camera detections with estimated distance\n",
    "        \n",
    "        Args:\n",
    "            image_path: Path to the camera image\n",
    "            image_id: ID of the frame\n",
    "            save_path: Path to save the visualization (optional)\n",
    "            \n",
    "        Returns:\n",
    "            Visualization image\n",
    "        \"\"\"\n",
    "        if image_id not in self.image_objects:\n",
    "            print(f\"No objects found for image {image_id}\")\n",
    "            return None\n",
    "            \n",
    "        # Handle both JPG and PNG files\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            # Try alternative extensions\n",
    "            for ext in ['.jpg', '.png', '.jpeg']:\n",
    "                alt_path = os.path.splitext(image_path)[0] + ext\n",
    "                if os.path.exists(alt_path):\n",
    "                    img = cv2.imread(alt_path)\n",
    "                    if img is not None:\n",
    "                        print(f\"Found alternative image: {alt_path}\")\n",
    "                        break\n",
    "            \n",
    "            if img is None:\n",
    "                print(f\"Error: Could not load image {image_path}\")\n",
    "                return None\n",
    "        \n",
    "        # Make a copy of the image to ensure we don't modify the original\n",
    "        vis_img = img.copy()\n",
    "        \n",
    "        # Calculate collision risks for distance and risk visualization\n",
    "        collision_risks = self.calculate_collision_risk(image_id)\n",
    "        \n",
    "        # Draw camera detections with distance estimates and risk color coding\n",
    "        for obj_idx, obj in enumerate(self.image_objects[image_id]):\n",
    "            bbox = [int(x) for x in obj['bbox']]\n",
    "            \n",
    "            # Get risk data for this object\n",
    "            risk_data = collision_risks.get(obj_idx, None)\n",
    "            \n",
    "            if risk_data:\n",
    "                # Color based on risk (green to red)\n",
    "                risk_score = risk_data['risk_score']\n",
    "                in_path = risk_data['in_path']\n",
    "                \n",
    "                # Higher risk = more red, lower risk = more green\n",
    "                if risk_score > 0.5:\n",
    "                    color = (0, 0, 255)  # Red for high risk\n",
    "                elif risk_score > 0.3:\n",
    "                    color = (0, 165, 255)  # Orange for medium risk\n",
    "                else:\n",
    "                    color = (0, 255, 0)  # Green for low risk\n",
    "                \n",
    "                # Draw thicker box for objects in our path\n",
    "                thickness = 3 if in_path else 2\n",
    "                \n",
    "                # Get distance\n",
    "                distance = risk_data['distance']\n",
    "                ttc = risk_data['ttc']\n",
    "                \n",
    "                # Make sure the bounding box coordinates are valid\n",
    "                x1, y1, x2, y2 = max(0, bbox[0]), max(0, bbox[1]), min(vis_img.shape[1], bbox[2]), min(vis_img.shape[0], bbox[3])\n",
    "                \n",
    "                # Draw info\n",
    "                cv2.rectangle(vis_img, (x1, y1), (x2, y2), color, thickness)\n",
    "                \n",
    "                # Add distance and TTC information\n",
    "                info_text = f\"{obj['type']}: {distance:.1f}m, TTC: {ttc:.1f}s\"\n",
    "                cv2.putText(vis_img, info_text, (x1, max(15, y1 - 5)), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "                \n",
    "                # Add risk score\n",
    "                risk_text = f\"Risk: {risk_score:.2f}\"\n",
    "                cv2.putText(vis_img, risk_text, (x1, max(35, y1 - 25)), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "                \n",
    "                # Add simplified bird's eye view at the bottom of the image\n",
    "                img_h, img_w = vis_img.shape[:2]\n",
    "                bev_h, bev_w = 150, 100  # Bird's eye view size\n",
    "                bev_orig_x, bev_orig_y = img_w // 2, img_h - 30  # Origin position\n",
    "                \n",
    "                # Draw bird's eye view background\n",
    "                cv2.rectangle(vis_img, (img_w - bev_w - 10, img_h - bev_h - 10), \n",
    "                             (img_w - 10, img_h - 10), (255, 255, 255), -1)\n",
    "                \n",
    "                # Draw ego vehicle\n",
    "                cv2.rectangle(vis_img, (img_w - bev_w//2 - 15, img_h - 25), \n",
    "                             (img_w - bev_w//2 + 15, img_h - 15), (0, 0, 0), -1)\n",
    "                \n",
    "                # Draw object in BEV\n",
    "                # Scale distance and lateral position for visualization\n",
    "                scaled_dist = min(distance * 5, bev_h - 20)\n",
    "                scaled_lat = risk_data['lateral_position'] * 10\n",
    "                \n",
    "                obj_bev_x = int(img_w - bev_w//2 - scaled_lat)\n",
    "                obj_bev_y = int(img_h - 20 - scaled_dist)\n",
    "                \n",
    "                # Make sure coordinates are within bounds\n",
    "                obj_bev_x = max(img_w - bev_w - 5, min(obj_bev_x, img_w - 15))\n",
    "                obj_bev_y = max(img_h - bev_h - 5, min(obj_bev_y, img_h - 15))\n",
    "                \n",
    "                cv2.circle(vis_img, (obj_bev_x, obj_bev_y), 5, color, -1)\n",
    "            else:\n",
    "                # Default color if no risk data\n",
    "                # Make sure the bounding box coordinates are valid\n",
    "                x1, y1, x2, y2 = max(0, bbox[0]), max(0, bbox[1]), min(vis_img.shape[1], bbox[2]), min(vis_img.shape[0], bbox[3])\n",
    "                cv2.rectangle(vis_img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                cv2.putText(vis_img, obj['type'], (x1, max(15, y1 - 5)), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
    "        \n",
    "        # Add header with frame info\n",
    "        cv2.putText(vis_img, f\"Frame: {image_id}\", (10, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)\n",
    "                   \n",
    "        # Add collision warning summary  \n",
    "        warnings = self.generate_warnings(collision_risks)\n",
    "        if warnings:\n",
    "            warning_text = f\"WARNING: {len(warnings)} potential collisions detected!\"\n",
    "            cv2.putText(vis_img, warning_text, (10, 60), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "        \n",
    "        if save_path:\n",
    "            # Ensure directory exists\n",
    "            os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "            # Save the image\n",
    "            cv2.imwrite(save_path, vis_img)\n",
    "            print(f\"Saved visualization to {save_path}\")\n",
    "            \n",
    "        return vis_img\n",
    "    \n",
    "    def process_frame(self, image_path, objects_path, image_id, velocity=13.8):\n",
    "        \"\"\"\n",
    "        Process a single frame with camera image\n",
    "        \n",
    "        Args:\n",
    "            image_path: Path to the camera image\n",
    "            objects_path: Path to the detected objects file\n",
    "            image_id: ID of the frame\n",
    "            velocity: Vehicle velocity in m/s\n",
    "            \n",
    "        Returns:\n",
    "            Processed objects for the frame\n",
    "        \"\"\"\n",
    "        # Load detected objects\n",
    "        self.load_image_objects(objects_path, image_id)\n",
    "        \n",
    "        # Calculate collision risks\n",
    "        collision_risks = self.calculate_collision_risk(image_id, velocity=velocity)\n",
    "        \n",
    "        # Generate warnings\n",
    "        warnings = self.generate_warnings(collision_risks)\n",
    "        \n",
    "        return collision_risks, warnings\n",
    "    \n",
    "    def process_dataset(self, dataset_config, output_path, visualize=True, velocity=13.8):\n",
    "        \"\"\"\n",
    "        Process an entire dataset with custom file paths\n",
    "        \n",
    "        Args:\n",
    "            dataset_config: Dictionary with paths to image, label files\n",
    "            output_path: Path to save the results\n",
    "            visualize: Whether to visualize and save results\n",
    "            velocity: Vehicle velocity in m/s\n",
    "        \"\"\"\n",
    "        # Create output directory if it doesn't exist\n",
    "        if not os.path.exists(output_path):\n",
    "            os.makedirs(output_path)\n",
    "            \n",
    "        # Process each frame\n",
    "        results = {}\n",
    "        for idx, frame_id in enumerate(dataset_config['frame_ids']):\n",
    "            print(f\"\\nProcessing frame {frame_id} ({idx+1}/{len(dataset_config['frame_ids'])})\")\n",
    "            \n",
    "            # Define paths for this frame\n",
    "            image_path = dataset_config['image_paths'][idx]\n",
    "            label_path = dataset_config['label_paths'][idx]\n",
    "            \n",
    "            # Process frame\n",
    "            collision_risks, warnings = self.process_frame(image_path, label_path, frame_id, velocity)\n",
    "            \n",
    "            # Visualize and save results\n",
    "            if visualize:\n",
    "                result_img = self.visualize_detections(\n",
    "                    image_path, \n",
    "                    frame_id,\n",
    "                    save_path=os.path.join(output_path, f'{frame_id}_detection.jpg')\n",
    "                )\n",
    "            \n",
    "            # Save warnings to file\n",
    "            with open(os.path.join(output_path, f'{frame_id}_warnings.txt'), 'w') as f:\n",
    "                if warnings:\n",
    "                    for warning in warnings:\n",
    "                        f.write(f\"{warning['level']}: {warning['message']} - Action: {warning['action']}\\n\")\n",
    "                else:\n",
    "                    f.write(\"No collision warnings for this frame.\\n\")\n",
    "                    \n",
    "            # Store results\n",
    "            results[frame_id] = {\n",
    "                'objects': self.image_objects.get(frame_id, []),\n",
    "                'collision_risks': collision_risks,\n",
    "                'warnings': warnings\n",
    "            }\n",
    "                    \n",
    "        print(\"Processing complete!\")\n",
    "        return results\n",
    "\n",
    "# Example usage with custom paths\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the camera-only detection system\n",
    "    \"\"\"\n",
    "    # Define your paths here\n",
    "    image_dir = \"/kaggle/working/object_vector\"  # Adjust to your actual image path\n",
    "    label_dir = \"/kaggle/input/kitti-dataset/data_object_label_2/training/label_2\"  # Adjust to your actual label path\n",
    "    calib_dir = \"/kaggle/input/kitti-dataset/data_object_calib/training/calib\"    # Adjust to your actual calib path\n",
    "    output_dir = \"/kaggle/working/output_collision_detection_1\"\n",
    "    \n",
    "    print(\"Starting camera-only collision detection...\")\n",
    "    \n",
    "    # Check if directories exist\n",
    "    for dir_path, dir_name in [\n",
    "        (image_dir, \"Image directory\"), \n",
    "        (label_dir, \"Label directory\"), \n",
    "        (calib_dir, \"Calibration directory\")\n",
    "    ]:\n",
    "        if not os.path.exists(dir_path):\n",
    "            print(f\"Warning: {dir_name} not found: {dir_path}\")\n",
    "    \n",
    "    # Check for image files and determine the correct extension\n",
    "    image_ext = '.png'  # Default\n",
    "    test_file = os.listdir(image_dir)[0] if os.path.exists(image_dir) and os.listdir(image_dir) else None\n",
    "    if test_file:\n",
    "        if test_file.endswith('.jpg') or test_file.endswith('.jpeg'):\n",
    "            image_ext = '.jpg'\n",
    "        print(f\"Using image extension: {image_ext}\")\n",
    "    \n",
    "    # Get list of frame IDs (look for both png and jpg)\n",
    "    if os.path.exists(image_dir):\n",
    "        frame_ids = []\n",
    "        for f in os.listdir(image_dir):\n",
    "            if f.endswith(image_ext):\n",
    "                frame_id = os.path.splitext(f)[0]\n",
    "                # Check if label file exists\n",
    "                if os.path.exists(os.path.join(label_dir, f\"{frame_id}.txt\")):\n",
    "                    frame_ids.append(frame_id)\n",
    "        \n",
    "        frame_ids = sorted(frame_ids)\n",
    "        \n",
    "        if not frame_ids:\n",
    "            print(f\"Warning: No valid image files found in {image_dir} with corresponding label files\")\n",
    "            # Try to find any images\n",
    "            image_files = [f for f in os.listdir(image_dir) if f.endswith(image_ext)]\n",
    "            print(f\"Found {len(image_files)} images, but no matching label files\")\n",
    "    else:\n",
    "        frame_ids = []\n",
    "        print(f\"Warning: Image directory not found: {image_dir}\")\n",
    "    \n",
    "    print(f\"Found {len(frame_ids)} valid frames with labels\")\n",
    "    \n",
    "    if not frame_ids:\n",
    "        print(\"Error: No valid frames found. Cannot proceed.\")\n",
    "        return\n",
    "    \n",
    "    # Map frame IDs to actual file paths\n",
    "    dataset_config = {\n",
    "        'frame_ids': frame_ids,\n",
    "        'image_paths': [os.path.join(image_dir, f\"{frame_id}{image_ext}\") for frame_id in frame_ids],\n",
    "        'label_paths': [os.path.join(label_dir, f\"{frame_id}.txt\") for frame_id in frame_ids],\n",
    "        'calib_paths': [os.path.join(calib_dir, f\"{frame_id}.txt\") for frame_id in frame_ids],\n",
    "    }\n",
    "    \n",
    "    # Initialize camera-only detection with the first calibration file\n",
    "    # Alternatively, you can load different calibration for each frame\n",
    "    detector = CameraOnlyDetection(dataset_config['calib_paths'][0])\n",
    "    \n",
    "    # Process the dataset\n",
    "    results = detector.process_dataset(dataset_config, output_dir, velocity=13.8)  # ~50 km/h\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
